I"©<h1 id="summary">Summary</h1>
<p>Deep learning models boast remarkable predictive capabilities, and they will work on image
recognition tasks within upload filters. But what else can these models tell about their
decisions? If these models are used in practice, they shall not only be work excellent but
be transparent. And yet the task of making models transparent appears underspecified if
it comes to the usage of these models in upload filters. Papers provide diverse solutions for
transparent models and offer myriad notions of what attributes render models transparent.
In this paper, I seek to refine the discourse on transparent models for image recognition.
&lt;/br&gt;
First, the motivation and underlying interest in transparent models get examined, finding
them to be diverse. Then, model properties and techniques thought to confer transparency
gets addressed, identifying SHAP values as a suitable method of doing so. Based on a prototype,
the feasibility of an explainable model within an upload filter gets discussed. Furthermore,
the assertion that explainable artificial intelligence can improve the user experience
of upload filters within social media gets questioned.</p>
:ET